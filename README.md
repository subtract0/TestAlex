# ACIMguide - A Custom AI Companion

This project aims to build a focused, gentle, and precise AI companion for practicing *A Course in Miracles (CE)*. It starts as a local Python-based chatbot and is designed to evolve into a full-fledged Android application backed by Firebase and the OpenAI Assistants API.

---

## Project Vision

The goal is to provide users with a reliable tool for guided chat, offering exact quotes with citations from the source material, and helpful features to support their spiritual practice.

## Current Status

**üöÄ PRODUCTION READY** - The project has evolved into a fully scalable, cloud-based AI companion with enterprise-grade features.

- **Backend**: Firebase Cloud Functions with OpenAI GPT-4o integration
- **Database**: Firestore with real-time capabilities and security rules
- **Features**: Rate limiting, token management, citation extraction, message streaming
- **Security**: Production-ready authentication and user-specific data access
- **Monitoring**: Comprehensive logging and error handling

**Ready for immediate deployment and mobile app development.**

## Development Roadmap

The full, detailed development plan is documented in `specs.md`. This roadmap outlines the three major phases to take this project from its current state to a production-ready application:

1.  **Phase 1: Harden and Refactor the Core Python Logic**
2.  **Phase 2: Transition to a Cloud-Based Backend (Firebase)**
3.  **Phase 3: Develop the Mobile Application (Android)**

Please refer to **[`specs.md`](./specs.md)** for a complete breakdown of the features, architecture, and step-by-step implementation plan.

---

### Local Setup (Previous Version)

For details on how to set up and run the previous local Python version of the application, please see the commit history prior to this update. The project is being rebooted to follow the new roadmap.
firestore.indexes.json # Database indexes ‚úÖ CREATED
```

## Development Status

### ‚úÖ Phase 1: Python Core Logic (COMPLETED)
- ‚úÖ **Consolidated Assistant Management**: `manage_assistant.py` with create/update/sync commands
- ‚úÖ **Structured Logging**: Implemented throughout Python codebase
- ‚úÖ **Error Handling**: Robust OpenAI API error handling
- ‚úÖ **File Sync**: Intelligent vector store file synchronization

### ‚úÖ Phase 2: Cloud Backend (COMPLETED)
- ‚úÖ **Firebase CLI**: Installed and authenticated
- ‚úÖ **GitHub CLI**: Installed and authenticated (subtract0)
- ‚úÖ **Firebase Project**: Connected to "acim-guide-test"
- ‚úÖ **Enhanced Cloud Functions**: Full API contract compliance
  - Token counting and usage tracking
  - Rate limiting (10 rpm per user)
  - Daily token caps (2000 tokens)
  - Citation extraction
  - Comprehensive logging and observability
- ‚úÖ **Firestore**: Configured with rules and indexes
- ‚úÖ **Message Streaming**: Firestore-based progressive response updates

### üéØ Phase 3: Mobile Application (READY TO START)
- üì± **Android App**: Architecture defined, ready for development
- üîê **Firebase Authentication**: Google Sign-In integration planned
- üé® **UI Components**: Chat interface, quick actions, settings designed

## üöÄ Quick Deployment

### Production Deployment (5 minutes)
```bash
# 1. Setup environment
source venv/bin/activate
pip install -r requirements.txt

# 2. Create assistant (first time only)
python manage_assistant.py create --name "CourseGPT" --model gpt-4o

# 3. Deploy to Firebase
firebase deploy

# 4. Test deployment
firebase functions:log --only chatWithAssistant
```

**üìñ Full deployment guide**: See [`DEPLOYMENT.md`](./DEPLOYMENT.md) for complete instructions.

## Usage Instructions

### Python Assistant Management

```bash
# Activate virtual environment
source venv/bin/activate

# Create a new assistant (requires OPENAI_API_KEY in .env)
python manage_assistant.py create

# Update assistant model
python manage_assistant.py update --model gpt-4o

# Sync files to vector store
python manage_assistant.py sync-files

# Run local chat (interactive mode)
python main.py

# Run single query
python main.py "What is forgiveness according to ACIM?"
```

### Firebase Cloud Functions

```bash
# Start local emulators
firebase emulators:start --only functions

# Deploy to production
firebase deploy --only functions

# View logs
firebase functions:log
```

### API Endpoints

#### `chatWithAssistant`
Callable HTTPS Function for chat interactions

**Request:**
```json
{
  "message": "string",
  "tone": "direct|gentle" // optional, defaults to "gentle"
}
```

**Response:**
```json
{
  "messageId": "string",
  "tokenIn": 123,
  "tokenOut": 456,
  "limitRemaining": 1544
}
```

#### `clearThread`
Callable HTTPS Function to reset user conversation

**Response:**
```json
{
  "threadId": "string",
  "message": "Thread cleared and reset successfully"
}
```

## Environment Variables

### Required
- `OPENAI_API_KEY`: OpenAI API key
- `ASSISTANT_ID`: OpenAI Assistant ID (auto-generated by manage_assistant.py)

### Optional
- `VECTOR_STORE_ID`: OpenAI Vector Store ID (auto-generated)
- `DAILY_OUT_TOKENS_CAP`: Daily token limit per user (default: 2000)
- `LOG_LEVEL`: Python logging level (default: INFO)

## Original Repo layout (suggested)

## Analytics events (names)
`app_open`, `sign_in_success`, `message_send`, `message_stream_start`, `message_stream_end`, `quick_action_used`, `limit_reached_daily_tokens`, `settings_changed`.

---

## Autonomous Agent Prompt System

This repository includes a sophisticated prompt system for autonomous agents that can handle various aspects of software development while maintaining strict adherence to ACIM principles and technical excellence.

### Prompt Structure

The prompt system is organized hierarchically:

```
prompts/
‚îú‚îÄ‚îÄ master_system_prompt.md          # Core foundational prompt
‚îú‚îÄ‚îÄ orchestration_protocol.md        # Agent coordination protocol
‚îú‚îÄ‚îÄ [role]_engineer.md               # Role-specific prompts
‚îî‚îÄ‚îÄ snippets/                        # Modular components
    ‚îú‚îÄ‚îÄ guardrails.md                # Code quality & architecture rules
    ‚îú‚îÄ‚îÄ docs_testing.md              # Documentation & testing standards
    ‚îî‚îÄ‚îÄ security_performance.md      # Security & performance guidelines
```

### Available Agent Roles

- **Backend Engineer** (`backend_engineer.md`) - Python/FastAPI backend development
- **Android Engineer** (`android_engineer.md`) - Kotlin/Jetpack Compose mobile development
- **Cloud Functions Engineer** (`cloud_functions_engineer.md`) - Firebase Cloud Functions
- **DevOps/SRE** (`devops_sre.md`) - Infrastructure and deployment
- **QA Tester** (`qa_tester.md`) - Testing and quality assurance
- **ACIM Scholar** (`acim_scholar.md`) - A Course in Miracles content validation

### Usage

#### Manual Prompt Assembly
```bash
# Render a complete prompt for a specific role
python scripts/render_prompt.py --role backend_engineer --output rendered_prompt.txt

# Include specific snippets
python scripts/render_prompt.py --role android_engineer --snippets guardrails docs_testing

# Validate prompt integrity
python scripts/render_prompt.py --validate-all
```

#### Programmatic Usage
```python
from scripts.render_prompt import PromptRenderer

# Initialize renderer
renderer = PromptRenderer()

# Render complete prompt for backend engineering
backend_prompt = renderer.render_role_prompt('backend_engineer', 
                                           snippets=['guardrails', 'security_performance'])

# Validate all prompts
validation_results = renderer.validate_all_prompts()
```

### Prompt Components

#### Master System Prompt
Contains the foundational rules, ACIM principles, and coding standards that apply to all agents. This serves as the base layer for all role-specific prompts.

#### Role-Specific Prompts
Each role inherits from the master prompt and adds specialized:
- Technical stack requirements
- Role-specific responsibilities
- Success criteria and metrics
- Handoff protocols between roles
- Specialized code examples and patterns

#### Snippet System
Modular components that can be mixed and matched:
- **Guardrails**: Code quality, architecture patterns, testing requirements
- **Docs/Testing**: Documentation standards, test coverage goals, CI/CD requirements
- **Security/Performance**: Security best practices, performance budgets, monitoring

### Validation and CI

The prompt system includes automated validation:

```yaml
# .github/workflows/validate-prompts.yml
name: Validate Prompts
on: [push, pull_request]
jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r scripts/requirements.txt
      - name: Validate prompt integrity
        run: python scripts/render_prompt.py --validate-all
```

### Design Principles

1. **Hierarchical Inheritance**: Role prompts inherit from master prompt
2. **Modular Composition**: Snippets can be mixed for specific contexts
3. **ACIM Fidelity**: All prompts maintain spiritual integrity of the project
4. **Technical Excellence**: Enforces best practices and quality standards
5. **Agent Coordination**: Clear handoff protocols between different roles
6. **Validation**: Automated checking for prompt completeness and integrity

### Extending the System

To add a new role:

1. Create `prompts/new_role_engineer.md`
2. Include the standard inheritance line: `*Inherits all principles, rules, and architecture from [Master System Prompt](./master_system_prompt.md)*`
3. Define role-specific scope, responsibilities, and success criteria
4. Add handoff protocols to/from other roles
5. Update `scripts/render_prompt.py` to recognize the new role
6. Add validation tests

To add a new snippet:

1. Create `prompts/snippets/new_snippet.md`
2. Focus on a specific, reusable concern (security, performance, etc.)
3. Use clear headings and actionable guidelines
4. Update the renderer to include the snippet in appropriate contexts

---

That's it. Ship the smallest valuable thing, then iterate.
